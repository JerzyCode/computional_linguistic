{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Notebook for finetuning model\n",
    "\n",
    "Model to finetune is allegro/herbert-base-cased. Do finetunningu zostaną zamrożone wszystkie warstwy oprócz ostatnich 4."
   ],
   "id": "71ac1ae103cf552"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-24T13:41:10.784634Z",
     "start_time": "2025-11-24T13:41:10.781277Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import softmax\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, EvalPrediction, Trainer, TrainingArguments"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T13:33:57.998651Z",
     "start_time": "2025-11-24T13:33:57.992146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HateClassifier(nn.Module):\n",
    "    def __init__(self, model_name=\"allegro/herbert-base-cased\", num_labels=2):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        hidden_size = self.bert.config.hidden_size\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for layer_idx in range(8, 12):\n",
    "            for param in self.bert.encoder.layer[layer_idx].parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        cls = out.last_hidden_state[:, 0, :]\n",
    "        x = self.dropout(cls)\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n"
   ],
   "id": "dfa56f5f3a510d66",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prepare Data",
   "id": "b056adc60b808e4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T13:19:39.435676Z",
     "start_time": "2025-11-24T13:19:39.361833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42, stratify=df[\"Class\"])"
   ],
   "id": "45490d41135fefe3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T13:34:01.519558Z",
     "start_time": "2025-11-24T13:34:01.515437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HateDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "\n",
    "        encoded = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoded[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoded[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }"
   ],
   "id": "e07a44d806525ba5",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T13:34:19.051081Z",
     "start_time": "2025-11-24T13:34:18.413803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-base-cased\")\n",
    "\n",
    "train_dataset = HateDataset(train_df[\"Text\"].tolist(), train_df[\"Class\"].tolist(), tokenizer)\n",
    "val_dataset = HateDataset(val_df[\"Text\"].tolist(), val_df[\"Class\"].tolist(), tokenizer)"
   ],
   "id": "434d6eeaa440c462",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "ad7e916d4bc47a09"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T13:32:59.461611Z",
     "start_time": "2025-11-24T13:32:59.454315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_pred: EvalPrediction) -> dict:\n",
    "    y_true = eval_pred.label_ids.ravel()\n",
    "    logits = torch.from_numpy(eval_pred.predictions)\n",
    "    y_pred_proba = softmax(logits, dim=1)[:, 1].numpy()\n",
    "\n",
    "    y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1\n",
    "    }"
   ],
   "id": "f678537d68470994",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T13:45:10.697791Z",
     "start_time": "2025-11-24T13:45:10.690864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(\n",
    "        model,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        output_dir=\"model_output\",\n",
    "        epochs=3,\n",
    "        batch_size=16,\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=50,\n",
    "        save_steps=50,\n",
    "        seed=42\n",
    "):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        logging_steps=logging_steps,\n",
    "        save_steps=save_steps,\n",
    "        save_total_limit=2,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "        seed=seed,\n",
    "        fp16=torch.cuda.is_available()\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        disable_tqdm=True\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    metrics = trainer.evaluate()\n",
    "    print(\"Final evaluation metrics:\", metrics)\n",
    "    return trainer, trainer.model"
   ],
   "id": "75dd0f7f071b9a7c",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T13:45:12.230420Z",
     "start_time": "2025-11-24T13:45:12.222472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_training(trainer):\n",
    "    df = pd.DataFrame(trainer.state.log_history)\n",
    "    df_train = df.dropna(subset=[\"loss\"])\n",
    "    df_eval = df.dropna(subset=[\"eval_loss\"])\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.plot(df_train[\"step\"], df_train[\"loss\"], label=\"Training Loss\")\n",
    "    plt.plot(df_eval[\"step\"], df_eval[\"eval_loss\"], label=\"Validation Loss\")\n",
    "\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training vs Validation Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_metrics(trainer):\n",
    "    df = pd.DataFrame(trainer.state.log_history)\n",
    "    metrics = [\"eval_accuracy\", \"eval_precision\", \"eval_recall\", \"eval_f1\"]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        df_metric = df.dropna(subset=[metric])\n",
    "        axes[i].plot(df_metric[\"step\"], df_metric[metric], marker='o')\n",
    "        axes[i].set_title(metric)\n",
    "        axes[i].set_xlabel(\"Step\")\n",
    "        axes[i].set_ylabel(metric)\n",
    "        axes[i].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "fd4d0fb10e1a2f19",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Try training",
   "id": "f36d1d691b02d2f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T13:45:52.666437Z",
     "start_time": "2025-11-24T13:45:13.782702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = HateClassifier()\n",
    "model.to(device)\n",
    "\n",
    "trainer, trained_model = train(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    output_dir=\"./hate_model\",\n",
    "    epochs=3,\n",
    "    batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    log_gging_steps=1,\n",
    ")"
   ],
   "id": "b480f36d21333aea",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[41]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m device = torch.device(\u001B[33m\"\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m model = \u001B[43mHateClassifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      3\u001B[39m model.to(device)\n\u001B[32m      5\u001B[39m trainer, trained_model = train(\n\u001B[32m      6\u001B[39m     model=model,\n\u001B[32m      7\u001B[39m     train_dataset=train_dataset,\n\u001B[32m   (...)\u001B[39m\u001B[32m     13\u001B[39m     log_gging_steps=\u001B[32m1\u001B[39m,\n\u001B[32m     14\u001B[39m )\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[26]\u001B[39m\u001B[32m, line 4\u001B[39m, in \u001B[36mHateClassifier.__init__\u001B[39m\u001B[34m(self, model_name, num_labels)\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, model_name=\u001B[33m\"\u001B[39m\u001B[33mallegro/herbert-base-cased\u001B[39m\u001B[33m\"\u001B[39m, num_labels=\u001B[32m2\u001B[39m):\n\u001B[32m      3\u001B[39m     \u001B[38;5;28msuper\u001B[39m().\u001B[34m__init__\u001B[39m()\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m     \u001B[38;5;28mself\u001B[39m.bert = \u001B[43mAutoModel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      5\u001B[39m     hidden_size = \u001B[38;5;28mself\u001B[39m.bert.config.hidden_size\n\u001B[32m      7\u001B[39m     \u001B[38;5;28mself\u001B[39m.classifier = nn.Linear(hidden_size, num_labels)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programming/Projects/university/term_3/computional_linguistic/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:604\u001B[39m, in \u001B[36m_BaseAutoModelClass.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[39m\n\u001B[32m    602\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m model_class.config_class == config.sub_configs.get(\u001B[33m\"\u001B[39m\u001B[33mtext_config\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m    603\u001B[39m         config = config.get_text_config()\n\u001B[32m--> \u001B[39m\u001B[32m604\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    605\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    606\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    607\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    608\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig.\u001B[34m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    609\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m, \u001B[39m\u001B[33m'\u001B[39m.join(c.\u001B[34m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m._model_mapping)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    610\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programming/Projects/university/term_3/computional_linguistic/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:277\u001B[39m, in \u001B[36mrestore_default_dtype.<locals>._wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    275\u001B[39m old_dtype = torch.get_default_dtype()\n\u001B[32m    276\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m277\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    278\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    279\u001B[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programming/Projects/university/term_3/computional_linguistic/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4903\u001B[39m, in \u001B[36mPreTrainedModel.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[39m\n\u001B[32m   4893\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   4894\u001B[39m     gguf_file\n\u001B[32m   4895\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m device_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   4896\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m ((\u001B[38;5;28misinstance\u001B[39m(device_map, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mdisk\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m device_map.values()) \u001B[38;5;129;01mor\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mdisk\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m device_map)\n\u001B[32m   4897\u001B[39m ):\n\u001B[32m   4898\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m   4899\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   4900\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mloaded from GGUF files.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   4901\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m4903\u001B[39m checkpoint_files, sharded_metadata = \u001B[43m_get_resolved_checkpoint_files\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4904\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4905\u001B[39m \u001B[43m    \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m=\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4906\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvariant\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvariant\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4907\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgguf_file\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgguf_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4908\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfrom_tf\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfrom_tf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4909\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfrom_flax\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfrom_flax\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4910\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_safetensors\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_safetensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4911\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4912\u001B[39m \u001B[43m    \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4913\u001B[39m \u001B[43m    \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4914\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4915\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4916\u001B[39m \u001B[43m    \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m=\u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4917\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4918\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcommit_hash\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4919\u001B[39m \u001B[43m    \u001B[49m\u001B[43mis_remote_code\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_auto_class\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   4920\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtransformers_explicit_filename\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtransformers_explicit_filename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4921\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4923\u001B[39m is_sharded = sharded_metadata \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   4924\u001B[39m is_quantized = hf_quantizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programming/Projects/university/term_3/computional_linguistic/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1070\u001B[39m, in \u001B[36m_get_resolved_checkpoint_files\u001B[39m\u001B[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001B[39m\n\u001B[32m   1067\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1068\u001B[39m         \u001B[38;5;66;03m# This repo has no safetensors file of any kind, we switch to PyTorch.\u001B[39;00m\n\u001B[32m   1069\u001B[39m         filename = _add_variant(WEIGHTS_NAME, variant)\n\u001B[32m-> \u001B[39m\u001B[32m1070\u001B[39m         resolved_archive_file = \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1071\u001B[39m \u001B[43m            \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mcached_file_kwargs\u001B[49m\n\u001B[32m   1072\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1073\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m resolved_archive_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m filename == _add_variant(WEIGHTS_NAME, variant):\n\u001B[32m   1074\u001B[39m     \u001B[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001B[39;00m\n\u001B[32m   1075\u001B[39m     resolved_archive_file = cached_file(\n\u001B[32m   1076\u001B[39m         pretrained_model_name_or_path,\n\u001B[32m   1077\u001B[39m         _add_variant(WEIGHTS_INDEX_NAME, variant),\n\u001B[32m   1078\u001B[39m         **cached_file_kwargs,\n\u001B[32m   1079\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programming/Projects/university/term_3/computional_linguistic/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:322\u001B[39m, in \u001B[36mcached_file\u001B[39m\u001B[34m(path_or_repo_id, filename, **kwargs)\u001B[39m\n\u001B[32m    264\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcached_file\u001B[39m(\n\u001B[32m    265\u001B[39m     path_or_repo_id: Union[\u001B[38;5;28mstr\u001B[39m, os.PathLike],\n\u001B[32m    266\u001B[39m     filename: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m    267\u001B[39m     **kwargs,\n\u001B[32m    268\u001B[39m ) -> Optional[\u001B[38;5;28mstr\u001B[39m]:\n\u001B[32m    269\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    270\u001B[39m \u001B[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001B[39;00m\n\u001B[32m    271\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    320\u001B[39m \u001B[33;03m    ```\u001B[39;00m\n\u001B[32m    321\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m322\u001B[39m     file = \u001B[43mcached_files\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilenames\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    323\u001B[39m     file = file[\u001B[32m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m file\n\u001B[32m    324\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m file\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programming/Projects/university/term_3/computional_linguistic/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:479\u001B[39m, in \u001B[36mcached_files\u001B[39m\u001B[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[39m\n\u001B[32m    476\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    477\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(full_filenames) == \u001B[32m1\u001B[39m:\n\u001B[32m    478\u001B[39m         \u001B[38;5;66;03m# This is slightly better for only 1 file\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m479\u001B[39m         \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    480\u001B[39m \u001B[43m            \u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    481\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfilenames\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    482\u001B[39m \u001B[43m            \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    483\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    484\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    485\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    486\u001B[39m \u001B[43m            \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m=\u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    487\u001B[39m \u001B[43m            \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    488\u001B[39m \u001B[43m            \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    489\u001B[39m \u001B[43m            \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    490\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    491\u001B[39m \u001B[43m            \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    492\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    493\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    494\u001B[39m         snapshot_download(\n\u001B[32m    495\u001B[39m             path_or_repo_id,\n\u001B[32m    496\u001B[39m             allow_patterns=full_filenames,\n\u001B[32m   (...)\u001B[39m\u001B[32m    505\u001B[39m             local_files_only=local_files_only,\n\u001B[32m    506\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programming/Projects/university/term_3/computional_linguistic/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001B[39m, in \u001B[36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    111\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[32m    112\u001B[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001B[34m__name__\u001B[39m, has_token=has_token, kwargs=kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programming/Projects/university/term_3/computional_linguistic/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1010\u001B[39m, in \u001B[36mhf_hub_download\u001B[39m\u001B[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001B[39m\n\u001B[32m    990\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _hf_hub_download_to_local_dir(\n\u001B[32m    991\u001B[39m         \u001B[38;5;66;03m# Destination\u001B[39;00m\n\u001B[32m    992\u001B[39m         local_dir=local_dir,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1007\u001B[39m         local_files_only=local_files_only,\n\u001B[32m   1008\u001B[39m     )\n\u001B[32m   1009\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1010\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_hf_hub_download_to_cache_dir\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1011\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Destination\u001B[39;49;00m\n\u001B[32m   1012\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1013\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# File info\u001B[39;49;00m\n\u001B[32m   1014\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrepo_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrepo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1015\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1016\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1017\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1018\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# HTTP info\u001B[39;49;00m\n\u001B[32m   1019\u001B[39m \u001B[43m        \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1020\u001B[39m \u001B[43m        \u001B[49m\u001B[43metag_timeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43metag_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1021\u001B[39m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhf_headers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1022\u001B[39m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1023\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1024\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Additional options\u001B[39;49;00m\n\u001B[32m   1025\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1026\u001B[39m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1027\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programming/Projects/university/term_3/computional_linguistic/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1171\u001B[39m, in \u001B[36m_hf_hub_download_to_cache_dir\u001B[39m\u001B[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001B[39m\n\u001B[32m   1168\u001B[39m \u001B[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001B[39;00m\n\u001B[32m   1170\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m WeakFileLock(lock_path):\n\u001B[32m-> \u001B[39m\u001B[32m1171\u001B[39m     \u001B[43m_download_to_tmp_and_move\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1172\u001B[39m \u001B[43m        \u001B[49m\u001B[43mincomplete_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblob_path\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m.incomplete\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1173\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdestination_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblob_path\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1174\u001B[39m \u001B[43m        \u001B[49m\u001B[43murl_to_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43murl_to_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1175\u001B[39m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1176\u001B[39m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1177\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexpected_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexpected_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1178\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1179\u001B[39m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1180\u001B[39m \u001B[43m        \u001B[49m\u001B[43metag\u001B[49m\u001B[43m=\u001B[49m\u001B[43metag\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1181\u001B[39m \u001B[43m        \u001B[49m\u001B[43mxet_file_data\u001B[49m\u001B[43m=\u001B[49m\u001B[43mxet_file_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1182\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1183\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os.path.exists(pointer_path):\n\u001B[32m   1184\u001B[39m         _create_symlink(blob_path, pointer_path, new_blob=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programming/Projects/university/term_3/computional_linguistic/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1723\u001B[39m, in \u001B[36m_download_to_tmp_and_move\u001B[39m\u001B[34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001B[39m\n\u001B[32m   1721\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m xet_file_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m is_xet_available():\n\u001B[32m   1722\u001B[39m     logger.debug(\u001B[33m\"\u001B[39m\u001B[33mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1723\u001B[39m     \u001B[43mxet_get\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1724\u001B[39m \u001B[43m        \u001B[49m\u001B[43mincomplete_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mincomplete_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1725\u001B[39m \u001B[43m        \u001B[49m\u001B[43mxet_file_data\u001B[49m\u001B[43m=\u001B[49m\u001B[43mxet_file_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1726\u001B[39m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1727\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexpected_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexpected_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1728\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdisplayed_filename\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1729\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1730\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1731\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m xet_file_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m constants.HF_HUB_DISABLE_XET:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programming/Projects/university/term_3/computional_linguistic/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:615\u001B[39m, in \u001B[36mxet_get\u001B[39m\u001B[34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001B[39m\n\u001B[32m    612\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(displayed_filename) > \u001B[32m40\u001B[39m:\n\u001B[32m    613\u001B[39m     displayed_filename = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdisplayed_filename[:\u001B[32m40\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m(…)\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m615\u001B[39m progress_cm = \u001B[43m_get_progress_bar_context\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    616\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdesc\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdisplayed_filename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    617\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlog_level\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlogger\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgetEffectiveLevel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    618\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtotal\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexpected_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    619\u001B[39m \u001B[43m    \u001B[49m\u001B[43minitial\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    620\u001B[39m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mhuggingface_hub.xet_get\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    621\u001B[39m \u001B[43m    \u001B[49m\u001B[43m_tqdm_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_tqdm_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    622\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    624\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m progress_cm \u001B[38;5;28;01mas\u001B[39;00m progress:\n\u001B[32m    626\u001B[39m     \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mprogress_updater\u001B[39m(progress_bytes: \u001B[38;5;28mfloat\u001B[39m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programming/Projects/university/term_3/computional_linguistic/.venv/lib/python3.12/site-packages/huggingface_hub/utils/tqdm.py:299\u001B[39m, in \u001B[36m_get_progress_bar_context\u001B[39m\u001B[34m(desc, log_level, total, initial, unit, unit_scale, name, _tqdm_bar)\u001B[39m\n\u001B[32m    294\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m nullcontext(_tqdm_bar)\n\u001B[32m    295\u001B[39m     \u001B[38;5;66;03m# ^ `contextlib.nullcontext` mimics a context manager that does nothing\u001B[39;00m\n\u001B[32m    296\u001B[39m     \u001B[38;5;66;03m#   Makes it easier to use the same code path for both cases but in the later\u001B[39;00m\n\u001B[32m    297\u001B[39m     \u001B[38;5;66;03m#   case, the progress bar is not closed when exiting the context manager.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m299\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    300\u001B[39m \u001B[43m    \u001B[49m\u001B[43munit\u001B[49m\u001B[43m=\u001B[49m\u001B[43munit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    301\u001B[39m \u001B[43m    \u001B[49m\u001B[43munit_scale\u001B[49m\u001B[43m=\u001B[49m\u001B[43munit_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    302\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtotal\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtotal\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    303\u001B[39m \u001B[43m    \u001B[49m\u001B[43minitial\u001B[49m\u001B[43m=\u001B[49m\u001B[43minitial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    304\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdesc\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdesc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    305\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdisable\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_tqdm_disabled\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlog_level\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlog_level\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    306\u001B[39m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[43m=\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    307\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programming/Projects/university/term_3/computional_linguistic/.venv/lib/python3.12/site-packages/tqdm/std.py:665\u001B[39m, in \u001B[36mtqdm.__new__\u001B[39m\u001B[34m(cls, *_, **__)\u001B[39m\n\u001B[32m    663\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__new__\u001B[39m(\u001B[38;5;28mcls\u001B[39m, *_, **__):\n\u001B[32m    664\u001B[39m     instance = \u001B[38;5;28mobject\u001B[39m.\u001B[34m__new__\u001B[39m(\u001B[38;5;28mcls\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m665\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_lock\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# also constructs lock if non-existent\u001B[39;49;00m\n\u001B[32m    666\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_instances\u001B[49m\u001B[43m.\u001B[49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43minstance\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    667\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# create monitoring thread\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programming/Projects/university/term_3/computional_linguistic/.venv/lib/python3.12/site-packages/tqdm/std.py:111\u001B[39m, in \u001B[36mTqdmDefaultWriteLock.__enter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    110\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__enter__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m111\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programming/Projects/university/term_3/computional_linguistic/.venv/lib/python3.12/site-packages/tqdm/std.py:104\u001B[39m, in \u001B[36mTqdmDefaultWriteLock.acquire\u001B[39m\u001B[34m(self, *a, **k)\u001B[39m\n\u001B[32m    102\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34macquire\u001B[39m(\u001B[38;5;28mself\u001B[39m, *a, **k):\n\u001B[32m    103\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m lock \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.locks:\n\u001B[32m--> \u001B[39m\u001B[32m104\u001B[39m         \u001B[43mlock\u001B[49m\u001B[43m.\u001B[49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
