{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6b0b5ab",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1fbeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from speakleash import Speakleash\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Iterator, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea2e160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATASET = \"wolne_lektury_corpus\"\n",
    "RAW_DATASET_DIR = \"./raw_data\"\n",
    "PREPARED_DATASET_DIR = \"./prepared_data\"\n",
    "\n",
    "os.makedirs(RAW_DATASET_DIR, exist_ok=True)\n",
    "os.makedirs(PREPARED_DATASET_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "585ec525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents count: 6619\n"
     ]
    }
   ],
   "source": [
    "sl = Speakleash(RAW_DATASET_DIR)\n",
    "training_speakleash_data = sl.get(TRAINING_DATASET)\n",
    "docs = list(training_speakleash_data.data)\n",
    "\n",
    "print(f\"Documents count: {training_speakleash_data.documents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22a67f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_document(doc: str) -> str:\n",
    "    filtered_doc = \"\"\n",
    "    lines = doc.split(\"\\n\")\n",
    "    for text_line in lines:\n",
    "        if len(text_line) > 20:\n",
    "            filtered_doc += text_line + \"\\n\"\n",
    "\n",
    "    return filtered_doc\n",
    "\n",
    "\n",
    "def save_text_data(path: str, docs: List[str]):\n",
    "    text_data = \"\\n\".join(docs)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "\n",
    "    print(f\"Saved data at: {path}\")\n",
    "\n",
    "\n",
    "def load_text_data(path: str) -> str:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b2917f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_docs.len = 1080\n",
      "train_docs.len = 120\n",
      "Saved data at: ./prepared_data/train.txt\n",
      "Saved data at: ./prepared_data/eval.txt\n"
     ]
    }
   ],
   "source": [
    "docs = list(training_speakleash_data.data)[:1200]\n",
    "filtered_docs = [filter_document(doc) for doc in docs]\n",
    "\n",
    "n = len(filtered_docs)\n",
    "\n",
    "split_idx = int(0.90 * n)\n",
    "train_docs = filtered_docs[:split_idx]\n",
    "eval_docs = filtered_docs[split_idx:]\n",
    "\n",
    "print(f\"train_docs.len = {len(train_docs)}\")\n",
    "print(f\"train_docs.len = {len(eval_docs)}\")\n",
    "\n",
    "save_text_data(path=os.path.join(PREPARED_DATASET_DIR, \"train.txt\"), docs=train_docs)\n",
    "save_text_data(path=os.path.join(PREPARED_DATASET_DIR, \"eval.txt\"), docs=eval_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d22573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = load_text_data(os.path.join(PREPARED_DATASET_DIR, \"train.txt\"))\n",
    "eval_text = load_text_data(os.path.join(PREPARED_DATASET_DIR, \"eval.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b372d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"radlab/polish-gpt2-small-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computional-linguistic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
